{"cells":[{"cell_type":"markdown","metadata":{"id":"KjCTmSHoRfkR"},"source":["#### 登入google帳戶"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19100,"status":"ok","timestamp":1654963955645,"user":{"displayName":"邱子軒","userId":"15678604503133980085"},"user_tz":-480},"id":"ubJ2ngj5u9wd","outputId":"3b929f95-63fa-4108-83d1-b0e3d74d2084"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["import math\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","import cv2\n","import os\n","import warnings\n","from google.colab import drive\n","drive.mount('/content/drive')\n","MAIN_DIR = '/content/drive/MyDrive/ourdata_v2/' #the main directory of this project"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2665,"status":"ok","timestamp":1654962715663,"user":{"displayName":"邱子軒","userId":"15678604503133980085"},"user_tz":-480},"id":"Iwc_zwG9zzTU","outputId":"cad94a05-51d1-4b11-f65d-42d27370bf0d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"UqyP6dqXE7uF"},"source":["#### 測試照片"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"j2aDf8lu3mAB"},"outputs":[],"source":["#load a single image as a test \n","from keras.preprocessing import image\n","test_image = image.load_img('/content/drive/MyDrive/ourdata_v2/test/paper/IMG_6922.jpg')\n","test_image"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":820,"status":"ok","timestamp":1654962762175,"user":{"displayName":"邱子軒","userId":"15678604503133980085"},"user_tz":-480},"id":"wIfNMGTSKM5w","outputId":"b62a4cfe-d8f5-4ecd-a5e8-0d7a395abca4"},"outputs":[{"name":"stdout","output_type":"stream","text":["(3024, 3024, 3)\n","(3024, 3024, 3)\n"]}],"source":["#load image and transform to 3D array - image array shape is 384 x 512 pixels, colour channels = 3 (RGB)\n","img_array = image.img_to_array(test_image)\n","print(img_array.shape)\n","#process for transforming an image to an array -- one way to do it \n","img_array = keras.applications.efficientnet.preprocess_input(img_array)\n","print(img_array.shape)"]},{"cell_type":"markdown","metadata":{"id":"2c7XnEW7FG2h"},"source":["#### 對資料進行data argumentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uEaRNjxvW0Kr"},"outputs":[],"source":["def resize_img(img):\n","  image_array = image.img_to_array(img)\n","  image_array = cv2.resize(image_array, (380,380))\n","  return image_array\n","\n","#隨機翻轉或擷取，且照片被整理為(380,380,3)\n","def center_process_img(img):\n","  cropped = resize_img(img)\n","  return np.flip(cropped, axis=0)\n","\n","    \n","def random_process_img(img):\n","  cropped = resize_img(img)\n","  return np.flip(cropped, axis=1)\n"]},{"cell_type":"markdown","metadata":{"id":"f3tWSMItarZu"},"source":["測試Augment images through random cropping & flipping"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vCA_k85KklxB"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","test_image = image.load_img('/content/drive/MyDrive/ourdata_v2/test/paper/IMG_6922.jpg')\n","center_cropped_test = image.array_to_img(center_process_img(test_image))\n","random_cropped_test = image.array_to_img(random_process_img(test_image))\n","\n","fig, ax = plt.subplots(2, 2)\n","fig.set_figheight(10)\n","fig.set_figwidth(10)\n","\n","ax[0, 0].imshow(test_image)\n","ax[0, 0].set_title('Original Image')\n","ax[0, 0].axis('off')\n","\n","ax[0, 1].imshow(center_cropped_test)\n","ax[0, 1].set_title('Center Crop')\n","ax[0, 1].axis('off')\n","\n","ax[1, 0].imshow(random_cropped_test)\n","ax[1, 0].set_title('Random Crop')\n","ax[1, 0].axis('off')\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"v5fpp7qAwTjG"},"source":["#### 將訓練、驗證及測試資料匯進list裡面"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nVsz-11QaJGJ"},"outputs":[],"source":["TEST_PATH = os.path.join(MAIN_DIR, 'test')\n","TRAIN_PATH = os.path.join(MAIN_DIR, 'train')\n","print(TEST_PATH)\n","#create lists to write processed images into \n","X_test_list = []\n","y_test_list = []\n","\n","X_train_list = []\n","y_train_list = []\n","\n","folder_names = ['paper', 'can', 'paper_container', 'plastic', 'trash']\n","\n","#connect to test image folder\n","#X_test_list的處理\n","for folder in folder_names:             #folder為資料夾名稱\n","  FOLDER_PATH = os.path.join(TEST_PATH, folder)\n","  for im in os.listdir(FOLDER_PATH):\n","    #load image and transform to array\n","    img = image.load_img(os.path.join(TEST_PATH, folder, im))      #合併(TEST_PATH, folder, im)路徑載入圖片\n","    center_img_array = center_process_img(img)                      # 對照片進行center_process_img函數的翻轉或擷取\n","    center_processed_img = keras.applications.efficientnet.preprocess_input(center_img_array)   #對處理後的照片進行preprocess\n","    random_img_array = random_process_img(img)                      # 對照片進行random_process_img函數的翻轉或擷取\n","    random_processed_img = keras.applications.efficientnet.preprocess_input(random_img_array)   #對處理後的照片進行preprocess\n","    # 新增原始照片\n","    ori_img_array = image.img_to_array(img)\n","    ori_resize_img = cv2.resize(ori_img_array, (380,380))\n","    #append processed image to new list\n","    X_test_list.append(list(ori_resize_img))\n","    X_test_list.append(list(center_processed_img))\n","    X_test_list.append(list(random_processed_img))\n","    #append label of processed image to new list\n","    y_test_list += [folder]    # 只是為了計算下面有多少圖片已進來\n","    y_test_list += [folder]    # 只是為了計算下面有多少圖片已進來\n","    y_test_list += [folder]    # 只是為了計算下面有多少圖片已進來\n","\n","    if len(y_test_list)%50 == 0:\n","      print(len(y_test_list), 'images loaded into test')\n","\n","#connect to train image folder \n","#X_train_list的處理\n","for folder in folder_names:\n","  FOLDER_PATH = os.path.join(TRAIN_PATH, folder)\n","  for im in os.listdir(FOLDER_PATH):\n","    #load image and transform to array\n","    img = image.load_img(os.path.join(TRAIN_PATH, folder, im))\n","    center_img_array = center_process_img(img)                      # 對照片進行center_process_img函數的翻轉或擷取\n","    center_processed_img = keras.applications.efficientnet.preprocess_input(center_img_array)   #對處理後的照片進行preprocess\n","    random_img_array = random_process_img(img)                      # 對照片進行random_process_img函數的翻轉或擷取\n","    random_processed_img = keras.applications.efficientnet.preprocess_input(random_img_array)   #對處理後的照片進行preproces\n","    # 新增原始照片\n","    ori_img_array = image.img_to_array(img)\n","    ori_resize_img = cv2.resize(ori_img_array, (380,380))\n","    #append processed image to new list\n","    X_train_list.append(list(ori_resize_img)) \n","    X_train_list.append(list(center_processed_img))\n","    X_train_list.append(list(random_processed_img))\n","    #append label of processed image to new list \n","    y_train_list += [folder] \n","    y_train_list += [folder] \n","    y_train_list += [folder] \n","\n","    if len(y_train_list)%50 == 0:\n","      print(len(y_train_list), 'images loaded into train')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ukdu_UIbp5EX"},"outputs":[],"source":["ori_img = image.img_to_array(img)\n","img1 = cv2.resize(ori_img, (380,380))\n","print(img1.shape)"]},{"cell_type":"markdown","metadata":{"id":"CAUDl8uOQ7Cf"},"source":["#### 將資料進行one hot encoding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lgz-fDVMylMn"},"outputs":[],"source":["#transform X variables to floats\n","X_train = np.array(X_train_list).astype(np.float32)\n","X_test = np.array(X_test_list).astype(np.float32)\n","print(X_train.shape)\n","print(X_test.shape)\n","print(y_train_list)\n","print(len(y_train_list))\n","print(len(y_test_list))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8DpslMIH7O0o"},"outputs":[],"source":["y_train = []\n","for i in range(len(y_train_list)):\n","  if y_train_list[i] == 'paper':\n","    y_train.append([1, 0, 0, 0, 0])\n","  elif y_train_list[i] == 'can':\n","    y_train.append([0, 1, 0, 0, 0])\n","  elif y_train_list[i] == 'paper_container':\n","    y_train.append([0, 0, 1, 0, 0])\n","  elif y_train_list[i] == 'plastic':\n","    y_train.append([0, 0, 0, 1, 0])\n","  elif y_train_list[i] == 'trash':\n","    y_train.append([0, 0, 0, 0, 1])\n","\n","y_train = np.array(y_train)\n","print(y_train)\n","print(y_train.shape)\n","\n","\n","y_test = []\n","for i in range(len(y_test_list)):\n","  if y_test_list[i] == 'paper':\n","    y_test.append([1, 0, 0, 0, 0])\n","  elif y_test_list[i] == 'can':\n","    y_test.append([0, 1, 0, 0, 0])\n","  elif y_test_list[i] == 'paper_container':\n","    y_test.append([0, 0, 1, 0, 0])\n","  elif y_test_list[i] == 'plastic':\n","    y_test.append([0, 0, 0, 1, 0])\n","  elif y_test_list[i] == 'trash':\n","    y_test.append([0, 0, 0, 0, 1])\n","\n","y_test = np.array(y_test)\n","print(y_test)\n","print(y_test.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JSQenUL6jZ85"},"outputs":[],"source":["train_full_shuffler = np.random.permutation(len(X_train))\n","X_train_full = X_train[train_full_shuffler]\n","y_train_full = y_train[train_full_shuffler]\n","print(train_full_shuffler)\n","print(X_train_full.shape)\n","valid_size = int(len(X_train)/5)\n","X_train, X_valid = X_train_full[:-valid_size], X_train_full[-valid_size:]\n","y_train, y_valid = y_train_full[:-valid_size], y_train_full[-valid_size:]\n","\n","print(X_train.shape)\n","print(y_train.shape)\n","print(y_valid.shape)\n","print(y_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EAF62gqG9km9"},"outputs":[],"source":["#釋放資源\n","X_test_list, X_valid_list, X_train_list, y_test_list, y_valid_list, y_train_list = [], [], [], [], [], []"]},{"cell_type":"markdown","metadata":{"id":"-pNhcRozQ6AV"},"source":["#### 建立模型"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MT_DHDxkQ2C0"},"outputs":[],"source":["base_model = keras.applications.EfficientNetB4(weights=\"imagenet\", include_top=False, input_shape=(380, 380, 3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FwlS3tbhXubC"},"outputs":[],"source":["#freeze the base model \n","base_model.trainable = False\n","\n","#define the type of NN architecture - sequential model specifies a linear stack of layers \n","model = keras.models.Sequential()\n","\n","#add the pre-trained model\n","model.add(base_model)\n","\n","#pool layer to prepare data as input into dense layer \n","model.add(keras.layers.GlobalAveragePooling2D())\n","model.add(keras.layers.Dense(256, activation='relu'))\n","#batch normalization layer re-centers and re-scales the network - helps accelerate training\n","model.add(keras.layers.BatchNormalization())\n","#dropout layer - temporarily deactivates 20% of the nodes in the network each epoch to redistribute weights/help network concentrate on \"weak\" features and prevent overfitting\n","model.add(keras.layers.Dropout(0.2))\n","#flatten layer to single array for input into dense layer \n","model.add(keras.layers.Flatten())\n","# prediction layer - 5 neurons = 5 category outputs, and softmax to normalize the output of the network to a probability distribution over the predicted output classes \n","model.add(keras.layers.Dense(5, activation='softmax'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sLh0JUBWSmqd"},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cI3zlPfcRklb"},"outputs":[],"source":["#compile model, specify sparse categorical crossentropy for classification and evaluate accuracy\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"hRkVXpBWm670"},"source":["#### 訓練模型"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jvTaREEXSXBb"},"outputs":[],"source":["#train model for 40 epochs \n","history = model.fit(X_train, y_train, epochs=20, validation_data = (X_valid, y_valid))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JtxMxwHvw-k_"},"outputs":[],"source":["score = model.evaluate(X_test, y_test, verbose=0)\n","print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"]},{"cell_type":"markdown","metadata":{"id":"7juzYwDSo2N-"},"source":["#### 測試資料結果呈現\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-4DvyB7U8rj2"},"outputs":[],"source":["incorrect = dict()\n","x = np.where(y_test[0] == 1)[0][0]\n","print(len(X_test))\n","for idx, predictions in enumerate(model.predict(X_test)):       #predictions為各分類機率的陣列\n","  print(idx, predictions)\n","  if np.argmax(predictions) != np.where(y_test[idx] == 1)[0][0]:\n","    incorrect[idx] = {'Predicted': np.argmax(predictions), 'Actual': y_test[idx][0]}\n","\n","incorrect_preds = pd.DataFrame.from_dict(incorrect, orient='index')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zvfVLzF39o-S"},"outputs":[],"source":["incorrect_preds.reset_index()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v0N73el7vjoG"},"outputs":[],"source":["predicted_class=np.argmax(model.predict(X_test), axis = -1)\n","predicted_class\n","print(predicted_class)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pFovL69qcrvd"},"outputs":[],"source":["def class_convert_x(classess):\n","    pred=[]\n","    for i in classess:\n","        if i ==0:\n","            pred.append('paper')\n","        elif i==1:\n","            pred.append('can')\n","        elif i==2:\n","            pred.append('paper_container')\n","        elif i==3:\n","            pred.append('Plastic')\n","        elif i==4:\n","            pred.append('Trash')\n","    return pred\n","\n","\n","def class_convert_y(classess):\n","    pred=[]\n","    for i in classess:\n","        if i[0]==1:\n","            pred.append('paper')\n","        elif i[1]==1:\n","            pred.append('can')\n","        elif i[2]==1:\n","            pred.append('paper_container')\n","        elif i[3]==1:\n","            pred.append('Plastic')\n","        elif i[4]==1:\n","            pred.append('Trash')\n","    return pred\n","\n","pred_class=class_convert_x(predicted_class)   #_x_test的預測結果\n","print(pred_class)\n","y_class=class_convert_y(y_test)         #y為答案\n","print(y_class)\n","print(len(pred_class), len(y_class))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oGw_2X7Bf8DN"},"outputs":[],"source":["corr=0\n","false=0\n","for i in range(len(y_class)):\n","    if y_class[i]==pred_class[i]:\n","         corr=corr+1\n","    else:\n","        false=false+1\n","        \n","print(\"Correct:\",corr)\n","print(\"False\",false)\n","print(corr/(corr+false))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3oCtCi4AkCI6"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","import seaborn as sb\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","\n","# Setting default fig size\n","size_ = (10,8)\n","cm=confusion_matrix(y_class,pred_class)\n","\n","array_list = []\n","for i in range(5):\n","  sum_row = np.sum(cm[i])\n","  ratio_row = np.around(cm[i]/sum_row, decimals=2)\n","  array_list.append(ratio_row)\n","cm = np.array(array_list)\n","\n","df_cm = pd.DataFrame(cm, range(cm.shape[0]), range(cm.shape[1]))\n","df_cm.columns = ['paper','can','paper_container','Plastic', 'Trash']\n","df_cm.index = ['paper','can','paper_container','Plastic', 'Trash']\n","\n","fig = plt.subplots(figsize=size_)\n","sb.set(font_scale=1)\n","sb.heatmap(df_cm, annot=True, annot_kws={\"size\": 10}, cmap=\"viridis\") # font size\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"haxWBo50t3CN"},"source":["#### 進行個別辨識"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OMk5BSb_bs2O"},"outputs":[],"source":["image_path = '/content/drive/Shareddrives/recycle/test_images/AnyConv.com__IMG_0664.jpg'\n","image.load_img(image_path, target_size=(380, 380))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JHvD2V02p_BF"},"outputs":[],"source":["def classify_image(my_image):\n","  custom_image = image.load_img(my_image, target_size=(380, 380))\n","  img_array = image.img_to_array(custom_image)\n","  processed_img = keras.applications.efficientnet.preprocess_input(img_array).astype(np.float32)\n","  swapped = np.moveaxis(processed_img, 0,1)\n","  arr4d = np.expand_dims(swapped, 0)\n","  max_index = np.argmax(model.predict(arr4d), axis = -1)\n","  new_prediction= class_convert_x(max_index)   #用class_convert進行文字分類\n","  value = model.predict(arr4d)\n","  print('Your item is: ', new_prediction[0])\n","\n","  for i in range(5):\n","    if value[0][i] > (value[0][max_index[0]])/2 and max_index[0] != i:\n","      new_prediction = class_convert_x([i])\n","      print('Your item is: ', new_prediction[0])\n","      print(value[0][i])\n","\n","  print(value)\n","  print(np.sum(value))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rV6ucc0KNArE"},"outputs":[],"source":["classify_image('/content/drive/Shareddrives/recycle/test_images/AnyConv.com__IMG_0663.jpg')"]},{"cell_type":"markdown","metadata":{"id":"Q1VfXjVdc5x9"},"source":["#### 儲存模型"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F21y4Sj0r_Pp"},"outputs":[],"source":["model.save(\"/content/drive/Shareddrives/recycle/first_test/my_model_v4.h5/\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"EfficientNetB4_Classification.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
